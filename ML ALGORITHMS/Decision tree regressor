import pandas as pd
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Load dataset
file_path = 'capstone.csv'  # Replace with your file path
data = pd.read_csv(file_path)

# Preprocessing
X = data.drop(columns=['Roof Fall Rate', 'S.no'])  # Exclude target and irrelevant columns
y = data['Roof Fall Rate']  # Target variable

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=36)

# Train the Decision Tree Regressor
model = DecisionTreeRegressor(random_state=42, max_depth=3)
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Calculate evaluation metrics
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

# Calculate normalized metrics
nrmse = rmse / (y_test.max() - y_test.min())
nmse = mse / y_test.var()
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100  # Mean Absolute Percentage Error
mad = np.mean(np.abs(y_test - y_pred))
# Print the results
print("Model Evaluation Metrics:")
print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"Normalized Root Mean Squared Error (NRMSE): {nrmse}")
print(f"Normalized Mean Squared Error (NMSE): {nmse}")
print(f"R-squared (R2): {r2}")

print(f"Mean Absolute Percentage Error (MAPE): {mape}%")
print(f"Mean Absolute Deviation (MAD): {mad}")


#to get decision tree visualization
import pandas as pd
from sklearn.tree import DecisionTreeRegressor, plot_tree
import matplotlib.pyplot as plt

# Load dataset
file_path = 'capstone.csv'  # Replace with your file path
data = pd.read_csv(file_path)

# Preprocessing
X = data.drop(columns=['Roof Fall Rate', 'S.no'])  # Exclude target and irrelevant columns
y = data['Roof Fall Rate']  # Target variable

# Train a Decision Tree Regressor
model = DecisionTreeRegressor(random_state=42, max_depth=3)  # Limit the depth to make it less clumsy
model.fit(X, y)

# Plot the decision tree
plt.figure(figsize=(20, 12))  # Larger figure for better readability
plot_tree(
    model,
    feature_names=X.columns,
    filled=True,
    rounded=True,
    fontsize=12,
    precision=2,
)
plt.title("Decision Tree Visualization", fontsize=16)
plt.show()
